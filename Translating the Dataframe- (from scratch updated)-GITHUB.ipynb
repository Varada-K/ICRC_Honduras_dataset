{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b7f109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plot\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94523c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/34/v3dd8zl14rl974rs2qmpy8zh0000gn/T/ipykernel_21370/1587428441.py:2: DtypeWarning: Columns (54) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df= pd.read_csv(\"honduras_triage_anon_data(Local)copy.csv\")\n"
     ]
    }
   ],
   "source": [
    "#reading the dataset\n",
    "df= pd.read_csv(\"honduras_triage_anon_data(Local)copy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ea53f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106906, 62)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8b1cee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Reading only the first 50 rows and selecting specific columns\n",
    "df_to_be_translated = df[['ADMISSION_NOTES', 'TRIAGE_NOTES', 'BACKGROUND_TRIAGE', 'OTHER_ALLERGIES']]\n",
    "\n",
    "# Saving the first 50 rows with selected columns to a demo file\n",
    "demo_file_path = 'To_be_translated.csv'  # Changed the file extension to .xlsx\n",
    "df_to_be_translated.to_csv(demo_file_path, index=False)\n",
    "\n",
    "print(\"File created successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4e94017",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'Your Key'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba870097",
   "metadata": {},
   "source": [
    "Testing if the key is valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36f3bf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key is valid.\n",
      "Available engines: {'object': 'list', 'data': [{'object': 'engine', 'id': 'whisper-1', 'ready': True, 'owner': 'openai-internal', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'gpt-4-turbo-2024-04-09', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'davinci-002', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'gpt-3.5-turbo', 'ready': True, 'owner': 'openai', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'gpt-4-turbo', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'dall-e-2', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'gpt-3.5-turbo-16k', 'ready': True, 'owner': 'openai-internal', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'tts-1-hd-1106', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'tts-1-hd', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'gpt-3.5-turbo-16k-0613', 'ready': True, 'owner': 'openai', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'text-embedding-3-large', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'gpt-4-1106-vision-preview', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'gpt-3.5-turbo-instruct-0914', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'gpt-4-0125-preview', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'gpt-3.5-turbo-instruct', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'gpt-3.5-turbo-0301', 'ready': True, 'owner': 'openai', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'gpt-3.5-turbo-0613', 'ready': True, 'owner': 'openai', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'tts-1', 'ready': True, 'owner': 'openai-internal', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'dall-e-3', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'gpt-3.5-turbo-1106', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'gpt-4-turbo-preview', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'gpt-4-1106-preview', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'babbage-002', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'tts-1-1106', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'gpt-4-vision-preview', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'text-embedding-3-small', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'gpt-4', 'ready': True, 'owner': 'openai', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'text-embedding-ada-002', 'ready': True, 'owner': 'openai-internal', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'gpt-3.5-turbo-0125', 'ready': True, 'owner': 'system', 'permissions': None, 'created': None}, {'object': 'engine', 'id': 'gpt-4-0613', 'ready': True, 'owner': 'openai', 'permissions': None, 'created': None}]}\n"
     ]
    }
   ],
   "source": [
    " import requests\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {api_key}'\n",
    "}\n",
    "\n",
    "def test_api_key():\n",
    "    try:\n",
    "        response = requests.get('https://api.openai.com/v1/engines', headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            print(\"API key is valid.\")\n",
    "            print(\"Available engines:\", response.json())\n",
    "        else:\n",
    "            print(f\"Failed to validate API key. Status code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while testing API key: {e}\")\n",
    "\n",
    "# Test the API key\n",
    "test_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a87a8e",
   "metadata": {},
   "source": [
    "Doing a simple query to get an output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac89e29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3 says:  How are you today\n",
      "\n",
      "I am an AI and do not have emotions like humans, but thank you for asking! I am functioning as expected and ready to assist you with any questions or tasks you may have. How can I help you?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_chatgpt_response(prompt):\n",
    "    url = \"https://api.openai.com/v1/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        'Authorization': f'Bearer {api_key}' # Replace with your actual API key\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo-instruct\",  # You can choose a different model here if needed---- \"davinci-002\"\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 60  # Adjust the number of tokens for response length\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"text\"]\n",
    "    else:\n",
    "        print(\"Failed to get response. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Hello GPT!\"\n",
    "response = get_chatgpt_response(prompt)\n",
    "if response:\n",
    "    print(\"GPT-3 says:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c410de",
   "metadata": {},
   "source": [
    "Testing all the engines available to us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ca0aed9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# # Dictionary to map engine names to their respective Engine ID and Owner (list of engines we have access to)\n",
    "# engines = {\n",
    "#     \"whisper-1\": \"Engine ID: whisper-1 - Owner: openai-internal\",\n",
    "#     \"davinci-002\": \"Engine ID: davinci-002 - Owner: system\",\n",
    "#     \"gpt-3.5-turbo\": \"Engine ID: gpt-3.5-turbo - Owner: openai\",\n",
    "#     \"dall-e-2\": \"Engine ID: dall-e-2 - Owner: system\",\n",
    "#     \"gpt-3.5-turbo-16k\": \"Engine ID: gpt-3.5-turbo-16k - Owner: openai-internal\",\n",
    "#     \"gpt-3.5-turbo-16k-0613\": \"Engine ID: gpt-3.5-turbo-16k-0613 - Owner: openai\",\n",
    "#     \"tts-1-hd-1106\": \"Engine ID: tts-1-hd-1106 - Owner: system\",\n",
    "#     \"tts-1-hd\": \"Engine ID: tts-1-hd - Owner: system\",\n",
    "#     \"text-embedding-3-large\": \"Engine ID: text-embedding-3-large - Owner: system\",\n",
    "#     \"gpt-4-1106-vision-preview\": \"Engine ID: gpt-4-1106-vision-preview - Owner: system\",\n",
    "#     \"gpt-3.5-turbo-instruct-0914\": \"Engine ID: gpt-3.5-turbo-instruct-0914 - Owner: system\",\n",
    "#     \"gpt-4-0125-preview\": \"Engine ID: gpt-4-0125-preview - Owner: system\",\n",
    "#     \"gpt-4-turbo-preview\": \"Engine ID: gpt-4-turbo-preview - Owner: system\",\n",
    "#     \"gpt-3.5-turbo-instruct\": \"Engine ID: gpt-3.5-turbo-instruct - Owner: system\",\n",
    "#     \"gpt-3.5-turbo-0301\": \"Engine ID: gpt-3.5-turbo-0301 - Owner: openai\",\n",
    "#     \"gpt-3.5-turbo-0613\": \"Engine ID: gpt-3.5-turbo-0613 - Owner: openai\",\n",
    "#     \"tts-1\": \"Engine ID: tts-1 - Owner: openai-internal\",\n",
    "#     \"dall-e-3\": \"Engine ID: dall-e-3 - Owner: system\",\n",
    "#     \"gpt-3.5-turbo-1106\": \"Engine ID: gpt-3.5-turbo-1106 - Owner: system\",\n",
    "#     \"gpt-4-1106-preview\": \"Engine ID: gpt-4-1106-preview - Owner: system\",\n",
    "#     \"babbage-002\": \"Engine ID: babbage-002 - Owner: system\",\n",
    "#     \"tts-1-1106\": \"Engine ID: tts-1-1106 - Owner: system\",\n",
    "#     \"gpt-4-vision-preview\": \"Engine ID: gpt-4-vision-preview - Owner: system\",\n",
    "#     \"text-embedding-3-small\": \"Engine ID: text-embedding-3-small - Owner: system\",\n",
    "#     \"gpt-4\": \"Engine ID: gpt-4 - Owner: openai\",\n",
    "#     \"text-embedding-ada-002\": \"Engine ID: text-embedding-ada-002 - Owner: openai-internal\",\n",
    "#     \"gpt-3.5-turbo-0125\": \"Engine ID: gpt-3.5-turbo-0125 - Owner: system\",\n",
    "#     \"gpt-4-0613\": \"Engine ID: gpt-4-0613 - Owner: openai\"\n",
    "# }\n",
    "\n",
    "# def get_chatgpt_response(prompt, engine_id):\n",
    "#     url = \"https://api.openai.com/v1/completions\"\n",
    "#     headers = {\n",
    "#         \"Content-Type\": \"application/json\",\n",
    "#         'Authorization': f'Bearer {api_key}' # Replace with your actual API key\n",
    "#     }\n",
    "#     data = {\n",
    "#         \"model\": engine_id,\n",
    "#         \"prompt\": prompt,  # Change prompt_name to prompt\n",
    "#         \"max_tokens\": 20\n",
    "#     }\n",
    "    \n",
    "#     response = requests.post(url, headers=headers, json=data)\n",
    "#     if response.status_code == 200:\n",
    "#         return response.json()[\"choices\"][0][\"text\"]\n",
    "#     else:\n",
    "#         print(f\"{engines[engine_id]} - Failed to get response. Status code:\", response.status_code)\n",
    "#         return None\n",
    "\n",
    "# # Example usage\n",
    "# prompt = \"Hello GPT!\"\n",
    "# for engine_id in engines:\n",
    "#     response = get_chatgpt_response(prompt, engine_id)\n",
    "#     if response:\n",
    "#         print(f\"{engines[engine_id]} - engine says:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12419da0",
   "metadata": {},
   "source": [
    "Summarization:\n",
    "\n",
    "| Engine ID            | Owner             | Response                                                                                                                                                                 |\n",
    "|----------------------|-------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| whisper-1            | openai-internal   | Failed to get response. Status code: 404                                                                                                                                |\n",
    "| davinci-002          | system            | How are you? Hope all is well on your side of the world. \"No more gas, no                                                                                               |\n",
    "| gpt-3.5-turbo        | openai            | Failed to get response. Status code: 404                                                                                                                                |\n",
    "| dall-e-2             | system            | Failed to get response. Status code: 403                                                                                                                                |\n",
    "| gpt-3.5-turbo-16k    | openai-internal   | Failed to get response. Status code: 404                                                                                                                                |\n",
    "| gpt-3.5-turbo-16k-0613| openai            | Failed to get response. Status code: 404                                                                                                                                |\n",
    "| tts-1-hd-1106        | system            | Failed to get response. Status code: 404                                                                                                                                |\n",
    "| tts-1-hd             | system            | Failed to get response. Status code: 404                                                                                                                                |\n",
    "| text-embedding-3-large| system           | Failed to get response. Status code: 403                                                                                                                                |\n",
    "| gpt-4-1106-vision-preview| system        | Failed to get response. Status code: 400                                                                                                                                |\n",
    "| gpt-3.5-turbo-instruct-0914| system       | Hello there! My name is GPT (Generative Pre-trained Transformer), I am an AI                                                                                             |\n",
    "| gpt-4-0125-preview   | system            | Failed to get response. Status code: 404                                                                                                                                |\n",
    "| gpt-4-turbo-preview  | system            | Failed to get response. Status code: 404                                                                                                                                |\n",
    "| gpt-3.5-turbo-instruct| system           | Hello there! I am just a language model AI, so I don't have personal emotions or                                                                                         |\n",
    "| gpt-3.5-turbo-0301   | openai            | Failed to get response. Status code: 404                                                                                                                                |\n",
    "| gpt-3.5-turbo-0613   | openai            | Failed to get response. Status code: 404                                                                                                                                |\n",
    "| tts-1                | openai-internal   | Failed to get response. Status code: 404                                                                                                                                |\n",
    "| dall-e-3             | system            | Failed to get response. Status code: 403                                                                                                                                |\n",
    "| gpt-3.5-turbo-1106   | system            | Failed to get response. Status code: 404                                                                                                                                |\n",
    "| gpt-4-1106-preview   | system            | I’m thinking of using one of your models to train an RL agent to play Dance Dance Revolution against                                                                     |\n",
    "| babbage-002          | system            | VIP will not let you broadcast. Like that so you can conduct poll and ask questions ps I dont                                                                            |\n",
    "| tts-1-1106           | system            | Failed to get response. Status code: 404                                                                                                                                |\n",
    "| gpt-4-vision-preview | system            | Failed to get response. Status code: 400                                                                                                                                |\n",
    "| text-embedding-3-small| system           | Failed to get response. Status code: 403                                                                                                                                |\n",
    "| gpt-4                | openai            | Failed to get response. Status code: 404                                                                                                                                |\n",
    "| text-embedding-ada-002| openai-internal  | GPTLG,GptlG, TlGptTmmGmGm                                                                                                                                                |\n",
    "| gpt-3.5-turbo-0125   | system            | Failed to get response. Status code: 404                                                                                                                                |\n",
    "| gpt-4-0613           | openai            | Failed to get response. Status code: 404                                                                                                                                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04252591",
   "metadata": {},
   "source": [
    "The ones that somewhat work effectively are:\n",
    "- davinci-002\n",
    "- gpt-3.5-turbo-instruct-0914\n",
    "- gpt-3.5-turbo-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35987945",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing with just one row\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the first row from the CSV file\n",
    "df = pd.read_csv('To_be_translated.csv', nrows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a277e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try getting a response from one row and one colum (one cell) and it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75030670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from googletrans import Translator\n",
    "import pandas as pd\n",
    "\n",
    "# Function to translate text from Spanish to English using Google Translate API\n",
    "def translate_to_english(text):\n",
    "    translator = Translator()\n",
    "    translated = translator.translate(text, src='es', dest='en')\n",
    "    return translated.text\n",
    "\n",
    "def get_chatgpt_response(prompt):\n",
    "    url = \"https://api.openai.com/v1/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        'Authorization': f'Bearer {api_key}' # Replace with your actual API key\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo-instruct\",  # You can choose a different model here if needed---- \"davinci-002\"\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 60  # Adjust the number of tokens for response length\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"text\"]\n",
    "    else:\n",
    "        print(\"Failed to get response. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "# Example usage with a DataFrame row\n",
    "def process_df_row(row):\n",
    "    # Translate the row from Spanish to English\n",
    "    translated_text = translate_to_english(row['ADMISSION_NOTES'])  # Change 'spanish_column' to your actual column name\n",
    "    \n",
    "    # Get GPT-3 response based on translated text\n",
    "    response = get_chatgpt_response(translated_text)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example usage with a DataFrame\n",
    "\n",
    "# Process each row of the DataFrame\n",
    "df['response'] = df.apply(process_df_row, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207db3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try one row, 4 columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05c5be21",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'Your Key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e16c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from googletrans import Translator\n",
    "\n",
    "# Function to translate text from Spanish to English using Google Translate API\n",
    "def translate_to_english(text):\n",
    "    translator = Translator()\n",
    "    translated = translator.translate(text, src='es', dest='en')\n",
    "    return translated.text\n",
    "\n",
    "def get_chatgpt_response(prompt):\n",
    "    \n",
    "    url = \"https://api.openai.com/v1/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        'Authorization': f'Bearer {api_key}' \n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo-instruct\",\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 60\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"text\"]\n",
    "    else:\n",
    "        print(\"Failed to get response. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "# Function to process each row of the DataFrame\n",
    "def process_df_row(row):\n",
    "    translated_columns = {}\n",
    "    for col in ['ADMISSION_NOTES', 'TRIAGE_NOTES', 'BACKGROUND_TRIAGE', 'OTHER_ALLERGIES']:\n",
    "        translated_text = translate_to_english(row[col])\n",
    "        generated_text = get_chatgpt_response(translated_text)\n",
    "        translated_columns[col+'_translated'] = generated_text\n",
    "    return translated_columns\n",
    "\n",
    "\n",
    "# Apply translation and GPT-3 response generation on each row\n",
    "translated_df = df.apply(process_df_row, axis=1, result_type='expand')\n",
    "\n",
    "# Concatenate the original DataFrame with the translated DataFrame\n",
    "final_df = pd.concat([df, translated_df], axis=1)\n",
    "\n",
    "# # Print the final DataFrame\n",
    "# print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5517c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('demo_translated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00607f1a",
   "metadata": {},
   "source": [
    "Observation: Have to adjust for Nan and the translation are very bizzare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa57f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets remove google translate API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5ef292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing with just one row\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the first row from the CSV file\n",
    "df = pd.read_csv('To_be_translated.csv', nrows=1)\n",
    "\n",
    "# # Print the dataframe\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49e2cc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your prompt: This is a spanish medical dataset, I want it translated into english. Every word is in spanish and needs translation. Do not add any additional information, just translate what is written.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"float\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m user_prompt \u001b[38;5;241m=\u001b[39m get_user_prompt()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Apply translation and GPT-3 response generation on each row with the user's prompt\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m translated_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(process_df_row, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, result_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpand\u001b[39m\u001b[38;5;124m'\u001b[39m, prompt\u001b[38;5;241m=\u001b[39muser_prompt)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Concatenate the original DataFrame with the translated DataFrame\u001b[39;00m\n\u001b[1;32m     43\u001b[0m final_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, translated_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9422\u001b[0m )\n\u001b[0;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(v)\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:133\u001b[0m, in \u001b[0;36mApply.__init__.<locals>.f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(x):\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[24], line 28\u001b[0m, in \u001b[0;36mprocess_df_row\u001b[0;34m(row, prompt)\u001b[0m\n\u001b[1;32m     26\u001b[0m translated_columns \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADMISSION_NOTES\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRIAGE_NOTES\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBACKGROUND_TRIAGE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOTHER_ALLERGIES\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 28\u001b[0m     generated_text \u001b[38;5;241m=\u001b[39m get_chatgpt_response(prompt \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m row[col])\n\u001b[1;32m     29\u001b[0m     translated_columns[col\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_translated\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m generated_text\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m translated_columns\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"float\") to str"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Function to get response from ChatGPT using a given prompt\n",
    "def get_chatgpt_response(prompt):\n",
    "    url = \"https://api.openai.com/v1/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        'Authorization': f'Bearer {api_key}' \n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"davinci-002\",  # Adjust the model as needed\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 60\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"text\"]\n",
    "    else:\n",
    "        print(\"Failed to get response. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "# Function to process each row of the DataFrame\n",
    "def process_df_row(row, prompt):\n",
    "    translated_columns = {}\n",
    "    for col in ['ADMISSION_NOTES', 'TRIAGE_NOTES', 'BACKGROUND_TRIAGE', 'OTHER_ALLERGIES']:\n",
    "        generated_text = get_chatgpt_response(prompt + ' ' + row[col])\n",
    "        translated_columns[col+'_translated'] = generated_text\n",
    "    return translated_columns\n",
    "\n",
    "# Function to interactively get the prompt from the user\n",
    "def get_user_prompt():\n",
    "    return input(\"Enter your prompt: \")\n",
    "\n",
    "# Get user prompt\n",
    "user_prompt = get_user_prompt()\n",
    "\n",
    "# Apply translation and GPT-3 response generation on each row with the user's prompt\n",
    "translated_df = df.apply(process_df_row, axis=1, result_type='expand', prompt=user_prompt)\n",
    "\n",
    "# Concatenate the original DataFrame with the translated DataFrame\n",
    "final_df = pd.concat([df, translated_df], axis=1)\n",
    "\n",
    "# Print the final DataFrame\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4569a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Need to adjust for the Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af8bbe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing with just one row\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the first row from the CSV file\n",
    "df = pd.read_csv('To_be_translated.csv', nrows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e87cf1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your prompt: Enter your prompt: This is a spanish medical dataset, I want it translated into english. Every word is in spanish and needs translation. Do not add any additional information, just translate what is written.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# Function to get response from ChatGPT using a given prompt\n",
    "def get_chatgpt_response(prompt):\n",
    "    url = \"https://api.openai.com/v1/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        'Authorization': f'Bearer {api_key}' \n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo-instruct\",  # Adjust the model as needed\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 60\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"text\"]\n",
    "    else:\n",
    "        print(\"Failed to get response. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "# Function to process each row of the DataFrame\n",
    "def process_df_row(row, prompt):\n",
    "    translated_columns = {}\n",
    "    for col in ['ADMISSION_NOTES', 'TRIAGE_NOTES', 'BACKGROUND_TRIAGE', 'OTHER_ALLERGIES']:\n",
    "        if not pd.isna(row[col]):  # Check if the value is not NaN\n",
    "            generated_text = get_chatgpt_response(prompt + ' ' + row[col])\n",
    "            translated_columns[col+'_translated'] = generated_text\n",
    "    return translated_columns\n",
    "\n",
    "# Function to interactively get the prompt from the user\n",
    "def get_user_prompt():\n",
    "    return input(\"Enter your prompt: \")\n",
    "\n",
    "# Get user prompt\n",
    "user_prompt = get_user_prompt()\n",
    "\n",
    "# Apply translation and GPT-3 response generation on each row with the user's prompt\n",
    "translated_df = df.apply(process_df_row, axis=1, result_type='expand', prompt=user_prompt)\n",
    "\n",
    "# Concatenate the original DataFrame with the translated DataFrame\n",
    "final_df = pd.concat([df, translated_df], axis=1)\n",
    "\n",
    "# # Print the final DataFrame\n",
    "# print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50a5c266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edf7b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## perfect but it completly ignores the column having a Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bc3679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your prompt: This is a spanish medical dataset, I want it translated into english. Every word is in spanish and needs translation. Do not add any additional information, just translate what is written.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# Function to get response from ChatGPT using a given prompt\n",
    "def get_chatgpt_response(prompt):\n",
    "    url = \"https://api.openai.com/v1/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        'Authorization': f'Bearer {api_key}' \n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo-instruct\",  # Adjust the model as needed\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 60\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"text\"]\n",
    "    else:\n",
    "        print(\"Failed to get response. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "# Function to process each row of the DataFrame\n",
    "def process_df_row(row, prompt):\n",
    "    translated_columns = {}\n",
    "    for col in ['ADMISSION_NOTES', 'TRIAGE_NOTES', 'BACKGROUND_TRIAGE', 'OTHER_ALLERGIES']:\n",
    "        if pd.notna(row[col]):  # Check if the value is not NaN\n",
    "            generated_text = get_chatgpt_response(prompt + ' ' + row[col])\n",
    "            translated_columns[col+'_translated'] = generated_text\n",
    "        else:\n",
    "            translated_columns[col+'_translated'] = np.nan\n",
    "    return translated_columns\n",
    "\n",
    "# Function to interactively get the prompt from the user\n",
    "def get_user_prompt():\n",
    "    return input(\"Enter your prompt: \")\n",
    "\n",
    "# Get user prompt\n",
    "user_prompt = get_user_prompt()\n",
    "\n",
    "# Apply translation and GPT-3 response generation on each row with the user's prompt\n",
    "translated_df = df.apply(process_df_row, axis=1, result_type='expand', prompt=user_prompt)\n",
    "\n",
    "# Concatenate the original DataFrame with the translated DataFrame\n",
    "final_df = pd.concat([df, translated_df], axis=1)\n",
    "\n",
    "# # Print the final DataFrame\n",
    "# print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a954f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53619db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing with just one row\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the first row from the CSV file\n",
    "df = pd.read_csv('To_be_translated.csv', nrows=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9658ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your prompt: This is a spanish medical dataset, I want it translated into english. Every word is in spanish and needs translation. Do not add any additional information, just translate what is written.\n"
     ]
    }
   ],
   "source": [
    "## Using the same code as above\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# Function to get response from ChatGPT using a given prompt\n",
    "def get_chatgpt_response(prompt):\n",
    "    url = \"https://api.openai.com/v1/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        'Authorization': f'Bearer {api_key}' \n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo-instruct\",  # Adjust the model as needed\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 60\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"text\"]\n",
    "    else:\n",
    "        print(\"Failed to get response. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "# Function to process each row of the DataFrame\n",
    "def process_df_row(row, prompt):\n",
    "    translated_columns = {}\n",
    "    for col in ['ADMISSION_NOTES', 'TRIAGE_NOTES', 'BACKGROUND_TRIAGE', 'OTHER_ALLERGIES']:\n",
    "        if pd.notna(row[col]):  # Check if the value is not NaN\n",
    "            generated_text = get_chatgpt_response(prompt + ' ' + row[col])\n",
    "            translated_columns[col+'_translated'] = generated_text\n",
    "        else:\n",
    "            translated_columns[col+'_translated'] = np.nan\n",
    "    return translated_columns\n",
    "\n",
    "# Function to interactively get the prompt from the user\n",
    "def get_user_prompt():\n",
    "    return input(\"Enter your prompt: \")\n",
    "\n",
    "# Get user prompt\n",
    "user_prompt = get_user_prompt()\n",
    "\n",
    "# Apply translation and GPT-3 response generation on each row with the user's prompt\n",
    "translated_df = df.apply(process_df_row, axis=1, result_type='expand', prompt=user_prompt)\n",
    "\n",
    "# Concatenate the original DataFrame with the translated DataFrame\n",
    "final_df = pd.concat([df, translated_df], axis=1)\n",
    "\n",
    "# # Print the final DataFrame\n",
    "# print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1232c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Awesome!! It works!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b3d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now lets try to do the same for 50 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66e812f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADMISSION_NOTES</th>\n",
       "      <th>TRIAGE_NOTES</th>\n",
       "      <th>BACKGROUND_TRIAGE</th>\n",
       "      <th>OTHER_ALLERGIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOLOR EN EPIGASTRIO</td>\n",
       "      <td>Pte con Historia de debilidad general, dolor a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amoxicilina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOLOR EN CUADRANTE INFERIOR IZQUIERDA</td>\n",
       "      <td>Ptes con historia de 1mes de evoluciÃ³n de pre...</td>\n",
       "      <td>Niega patologÃ­as \\r\\nOperada de apendicitis e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIFICULTAD PARA RESPIRAR</td>\n",
       "      <td>Px con dolor en Flanco derecho de 1 dÃ­a de ev...</td>\n",
       "      <td>Px deambulando, sin signos de bajo gasto</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALERGIA</td>\n",
       "      <td>Pte con hx dolor abdominal generalizado cefale...</td>\n",
       "      <td>Arritmia cardÃ­aca\\r\\nNiega otra patologia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOLOR EN FII PRESENTA NAUSEAS Y ESCALOFRIOS</td>\n",
       "      <td>Dolor en cuadrante inferior derecho inicio 5:3...</td>\n",
       "      <td>Ninguna</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ADMISSION_NOTES  \\\n",
       "0                         DOLOR EN EPIGASTRIO    \n",
       "1       DOLOR EN CUADRANTE INFERIOR IZQUIERDA    \n",
       "2                     DIFICULTAD PARA RESPIRAR   \n",
       "3                                      ALERGIA   \n",
       "4  DOLOR EN FII PRESENTA NAUSEAS Y ESCALOFRIOS   \n",
       "\n",
       "                                        TRIAGE_NOTES  \\\n",
       "0  Pte con Historia de debilidad general, dolor a...   \n",
       "1  Ptes con historia de 1mes de evoluciÃ³n de pre...   \n",
       "2  Px con dolor en Flanco derecho de 1 dÃ­a de ev...   \n",
       "3  Pte con hx dolor abdominal generalizado cefale...   \n",
       "4  Dolor en cuadrante inferior derecho inicio 5:3...   \n",
       "\n",
       "                                   BACKGROUND_TRIAGE OTHER_ALLERGIES  \n",
       "0                                                NaN    Amoxicilina   \n",
       "1  Niega patologÃ­as \\r\\nOperada de apendicitis e...             NaN  \n",
       "2          Px deambulando, sin signos de bajo gasto              NaN  \n",
       "3         Arritmia cardÃ­aca\\r\\nNiega otra patologia             NaN  \n",
       "4                                            Ninguna             NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the first row from the CSV file\n",
    "df = pd.read_csv('To_be_translated.csv',nrows=100)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "417aadd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e2704db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your prompt: This is a spanish medical dataset, I need every word to be translated in english\n"
     ]
    }
   ],
   "source": [
    "## Using the same code as above\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# Function to get response from ChatGPT using a given prompt\n",
    "def get_chatgpt_response(prompt):\n",
    "    url = \"https://api.openai.com/v1/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        'Authorization': f'Bearer {api_key}' \n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo-instruct\",  # Adjust the model as needed\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 60\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"text\"]\n",
    "    else:\n",
    "        print(\"Failed to get response. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "# Function to process each row of the DataFrame\n",
    "def process_df_row(row, prompt):\n",
    "    translated_columns = {}\n",
    "    for col in ['ADMISSION_NOTES', 'TRIAGE_NOTES', 'BACKGROUND_TRIAGE', 'OTHER_ALLERGIES']:\n",
    "        if pd.notna(row[col]):  # Check if the value is not NaN\n",
    "            generated_text = get_chatgpt_response(prompt + ' ' + row[col])\n",
    "            translated_columns[col+'_translated'] = generated_text\n",
    "        else:\n",
    "            translated_columns[col+'_translated'] = np.nan\n",
    "    return translated_columns\n",
    "\n",
    "# Function to interactively get the prompt from the user\n",
    "def get_user_prompt():\n",
    "    return input(\"Enter your prompt: \")\n",
    "\n",
    "# Get user prompt\n",
    "user_prompt = get_user_prompt()\n",
    "\n",
    "# Apply translation and GPT-3 response generation on each row with the user's prompt\n",
    "translated_df = df.apply(process_df_row, axis=1, result_type='expand', prompt=user_prompt)\n",
    "\n",
    "# Concatenate the original DataFrame with the translated DataFrame\n",
    "final_df = pd.concat([df, translated_df], axis=1)\n",
    "\n",
    "# # Print the final DataFrame\n",
    "# print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26aadd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to an Excel file\n",
    "final_df.to_excel(\"final_dataframe.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc757e38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
